{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Tuple\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>surgery</th>\n",
       "      <th>age</th>\n",
       "      <th>hospital_number</th>\n",
       "      <th>rectal_temp</th>\n",
       "      <th>pulse</th>\n",
       "      <th>respiratory_rate</th>\n",
       "      <th>temp_of_extremities</th>\n",
       "      <th>peripheral_pulse</th>\n",
       "      <th>mucous_membrane</th>\n",
       "      <th>...</th>\n",
       "      <th>packed_cell_volume</th>\n",
       "      <th>total_protein</th>\n",
       "      <th>abdomo_appearance</th>\n",
       "      <th>abdomo_protein</th>\n",
       "      <th>surgical_lesion</th>\n",
       "      <th>lesion_1</th>\n",
       "      <th>lesion_2</th>\n",
       "      <th>lesion_3</th>\n",
       "      <th>cp_data</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>adult</td>\n",
       "      <td>530001</td>\n",
       "      <td>38.1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>cool</td>\n",
       "      <td>reduced</td>\n",
       "      <td>dark_cyanotic</td>\n",
       "      <td>...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>serosanguious</td>\n",
       "      <td>3.4</td>\n",
       "      <td>yes</td>\n",
       "      <td>2209</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>adult</td>\n",
       "      <td>533836</td>\n",
       "      <td>37.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>cool</td>\n",
       "      <td>normal</td>\n",
       "      <td>pale_cyanotic</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>serosanguious</td>\n",
       "      <td>2.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>2208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>euthanized</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>adult</td>\n",
       "      <td>529812</td>\n",
       "      <td>38.3</td>\n",
       "      <td>120.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>cool</td>\n",
       "      <td>reduced</td>\n",
       "      <td>pale_pink</td>\n",
       "      <td>...</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>serosanguious</td>\n",
       "      <td>3.4</td>\n",
       "      <td>yes</td>\n",
       "      <td>5124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>lived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>adult</td>\n",
       "      <td>5262541</td>\n",
       "      <td>37.1</td>\n",
       "      <td>72.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>cold</td>\n",
       "      <td>reduced</td>\n",
       "      <td>pale_pink</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>2208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>lived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>adult</td>\n",
       "      <td>5299629</td>\n",
       "      <td>38.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal_pink</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>2.6</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>lived</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id surgery    age  hospital_number  rectal_temp  pulse  respiratory_rate  \\\n",
       "0   0     yes  adult           530001         38.1  132.0              24.0   \n",
       "1   1     yes  adult           533836         37.5   88.0              12.0   \n",
       "2   2     yes  adult           529812         38.3  120.0              28.0   \n",
       "3   3     yes  adult          5262541         37.1   72.0              30.0   \n",
       "4   4      no  adult          5299629         38.0   52.0              48.0   \n",
       "\n",
       "  temp_of_extremities peripheral_pulse mucous_membrane  ...  \\\n",
       "0                cool          reduced   dark_cyanotic  ...   \n",
       "1                cool           normal   pale_cyanotic  ...   \n",
       "2                cool          reduced       pale_pink  ...   \n",
       "3                cold          reduced       pale_pink  ...   \n",
       "4              normal           normal     normal_pink  ...   \n",
       "\n",
       "  packed_cell_volume total_protein abdomo_appearance abdomo_protein  \\\n",
       "0               57.0           8.5     serosanguious            3.4   \n",
       "1               33.0          64.0     serosanguious            2.0   \n",
       "2               37.0           6.4     serosanguious            3.4   \n",
       "3               53.0           7.0            cloudy            3.9   \n",
       "4               47.0           7.3            cloudy            2.6   \n",
       "\n",
       "  surgical_lesion lesion_1  lesion_2 lesion_3 cp_data     outcome  \n",
       "0             yes     2209         0        0      no        died  \n",
       "1             yes     2208         0        0      no  euthanized  \n",
       "2             yes     5124         0        0      no       lived  \n",
       "3             yes     2208         0        0     yes       lived  \n",
       "4              no        0         0        0     yes       lived  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1235 entries, 0 to 1234\n",
      "Data columns (total 29 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     1235 non-null   int64  \n",
      " 1   surgery                1235 non-null   object \n",
      " 2   age                    1235 non-null   object \n",
      " 3   hospital_number        1235 non-null   int64  \n",
      " 4   rectal_temp            1235 non-null   float64\n",
      " 5   pulse                  1235 non-null   float64\n",
      " 6   respiratory_rate       1235 non-null   float64\n",
      " 7   temp_of_extremities    1196 non-null   object \n",
      " 8   peripheral_pulse       1175 non-null   object \n",
      " 9   mucous_membrane        1214 non-null   object \n",
      " 10  capillary_refill_time  1229 non-null   object \n",
      " 11  pain                   1191 non-null   object \n",
      " 12  peristalsis            1215 non-null   object \n",
      " 13  abdominal_distention   1212 non-null   object \n",
      " 14  nasogastric_tube       1155 non-null   object \n",
      " 15  nasogastric_reflux     1214 non-null   object \n",
      " 16  nasogastric_reflux_ph  1235 non-null   float64\n",
      " 17  rectal_exam_feces      1045 non-null   object \n",
      " 18  abdomen                1022 non-null   object \n",
      " 19  packed_cell_volume     1235 non-null   float64\n",
      " 20  total_protein          1235 non-null   float64\n",
      " 21  abdomo_appearance      1187 non-null   object \n",
      " 22  abdomo_protein         1235 non-null   float64\n",
      " 23  surgical_lesion        1235 non-null   object \n",
      " 24  lesion_1               1235 non-null   int64  \n",
      " 25  lesion_2               1235 non-null   int64  \n",
      " 26  lesion_3               1235 non-null   int64  \n",
      " 27  cp_data                1235 non-null   object \n",
      " 28  outcome                1235 non-null   object \n",
      "dtypes: float64(7), int64(5), object(17)\n",
      "memory usage: 279.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Data Types\n",
    "df_train = df_train.astype({\"hospital_number\": 'category'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping null values: 1235\n",
      "After dropping null values: 771\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before dropping null values: {len(df_train)}\\nAfter dropping null values: {len(df_train.dropna(axis=0, how='any'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can consider dropping all rows with null values but I feel we may need to take a hybrid approach dropping some rows and columns (devil is in the details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rectal_temp</th>\n",
       "      <th>pulse</th>\n",
       "      <th>respiratory_rate</th>\n",
       "      <th>nasogastric_reflux_ph</th>\n",
       "      <th>packed_cell_volume</th>\n",
       "      <th>total_protein</th>\n",
       "      <th>abdomo_protein</th>\n",
       "      <th>lesion_1</th>\n",
       "      <th>lesion_2</th>\n",
       "      <th>lesion_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1235.0000</td>\n",
       "      <td>1235.000000</td>\n",
       "      <td>1235.000000</td>\n",
       "      <td>1235.000000</td>\n",
       "      <td>1235.000000</td>\n",
       "      <td>1235.000000</td>\n",
       "      <td>1235.000000</td>\n",
       "      <td>1235.000000</td>\n",
       "      <td>1235.000000</td>\n",
       "      <td>1235.000000</td>\n",
       "      <td>1235.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>617.0000</td>\n",
       "      <td>38.202186</td>\n",
       "      <td>79.574089</td>\n",
       "      <td>30.054251</td>\n",
       "      <td>4.382591</td>\n",
       "      <td>49.602429</td>\n",
       "      <td>21.388016</td>\n",
       "      <td>3.290931</td>\n",
       "      <td>3832.496356</td>\n",
       "      <td>14.612146</td>\n",
       "      <td>3.577328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>356.6581</td>\n",
       "      <td>0.788668</td>\n",
       "      <td>29.108638</td>\n",
       "      <td>16.452066</td>\n",
       "      <td>1.937357</td>\n",
       "      <td>10.535800</td>\n",
       "      <td>26.676453</td>\n",
       "      <td>1.589195</td>\n",
       "      <td>5436.733774</td>\n",
       "      <td>193.705735</td>\n",
       "      <td>88.858953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>35.400000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>308.5000</td>\n",
       "      <td>37.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2205.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>617.0000</td>\n",
       "      <td>38.200000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2209.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>925.5000</td>\n",
       "      <td>38.600000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>3205.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1234.0000</td>\n",
       "      <td>40.800000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>41110.000000</td>\n",
       "      <td>3112.000000</td>\n",
       "      <td>2209.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  rectal_temp        pulse  respiratory_rate  \\\n",
       "count  1235.0000  1235.000000  1235.000000       1235.000000   \n",
       "mean    617.0000    38.202186    79.574089         30.054251   \n",
       "std     356.6581     0.788668    29.108638         16.452066   \n",
       "min       0.0000    35.400000    30.000000          8.000000   \n",
       "25%     308.5000    37.800000    53.000000         18.000000   \n",
       "50%     617.0000    38.200000    76.000000         28.000000   \n",
       "75%     925.5000    38.600000   100.000000         36.000000   \n",
       "max    1234.0000    40.800000   184.000000         96.000000   \n",
       "\n",
       "       nasogastric_reflux_ph  packed_cell_volume  total_protein  \\\n",
       "count            1235.000000         1235.000000    1235.000000   \n",
       "mean                4.382591           49.602429      21.388016   \n",
       "std                 1.937357           10.535800      26.676453   \n",
       "min                 1.000000           23.000000       3.500000   \n",
       "25%                 2.000000           43.000000       6.600000   \n",
       "50%                 4.500000           48.000000       7.500000   \n",
       "75%                 6.000000           57.000000       9.100000   \n",
       "max                 7.500000           75.000000      89.000000   \n",
       "\n",
       "       abdomo_protein      lesion_1     lesion_2     lesion_3  \n",
       "count     1235.000000   1235.000000  1235.000000  1235.000000  \n",
       "mean         3.290931   3832.496356    14.612146     3.577328  \n",
       "std          1.589195   5436.733774   193.705735    88.858953  \n",
       "min          0.100000      0.000000     0.000000     0.000000  \n",
       "25%          2.000000   2205.000000     0.000000     0.000000  \n",
       "50%          3.000000   2209.000000     0.000000     0.000000  \n",
       "75%          4.300000   3205.000000     0.000000     0.000000  \n",
       "max         10.100000  41110.000000  3112.000000  2209.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                       1235\n",
       "surgery                     2\n",
       "age                         2\n",
       "hospital_number           255\n",
       "rectal_temp                43\n",
       "pulse                      50\n",
       "respiratory_rate           37\n",
       "temp_of_extremities         4\n",
       "peripheral_pulse            4\n",
       "mucous_membrane             6\n",
       "capillary_refill_time       3\n",
       "pain                        6\n",
       "peristalsis                 5\n",
       "abdominal_distention        4\n",
       "nasogastric_tube            3\n",
       "nasogastric_reflux          4\n",
       "nasogastric_reflux_ph      26\n",
       "rectal_exam_feces           5\n",
       "abdomen                     5\n",
       "packed_cell_volume         49\n",
       "total_protein              83\n",
       "abdomo_appearance           3\n",
       "abdomo_protein             54\n",
       "surgical_lesion             2\n",
       "lesion_1                   57\n",
       "lesion_2                    4\n",
       "lesion_3                    2\n",
       "cp_data                     2\n",
       "outcome                     3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATEGORIES IN COLUMNS\n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Column \t\t\t\t Unique Categories\n",
      "abdomo_appearance \t\t ['serosanguious', 'cloudy', 'clear', nan]\n",
      "hospital_number \t\t [530001, 533836, 529812, 5262541, 5299629, 529642, 534787, 529461, 528742, 529640, 528682, 530028, 528548, 528134, 528305, 534885, 5290482, 5279822, 533692, 535208, 528523, 529893, 534145, 530233, 529399, 530354, 528503, 529796, 527916, 530360, 528298, 533871, 529388, 527563, 534163, 529827, 535196, 535176, 529045, 527518, 527463, 529172, 528996, 533887, 528904, 535407, 533902, 523190, 534073, 534135, 5290409, 529160, 534917, 534784, 5299253, 534004, 534115, 529667, 5297159, 529427, 527677, 530612, 535415, 530561, 530242, 530002, 5289419, 529498, 529126, 5291409, 5287179, 530526, 5290759, 532110, 534293, 534280, 528214, 527933, 5283431, 528743, 529766, 529304, 530401, 527702, 529849, 534157, 534998, 529340, 530276, 527927, 534886, 527365, 528641, 528461, 528469, 529607, 533942, 529272, 528183, 533696, 528247, 535043, 530034, 534925, 530402, 535292, 529493, 528355, 534197, 530239, 529777, 530478, 534069, 533928, 528570, 528800, 528668, 530693, 528179, 528151, 530254, 528890, 534644, 530255, 529663, 535031, 534403, 528804, 528872, 528702, 535166, 535330, 528729, 529888, 529475, 5294539, 533750, 530334, 535130, 530439, 534624, 529628, 530366, 526639, 5301219, 529703, 528178, 527734, 529840, 534753, 534963, 5291329, 533885, 529518, 5297379, 534519, 521399, 529685, 529183, 530301, 527544, 527709, 5294369, 528248, 527758, 535085, 534933, 529428, 533847, 530251, 533738, 527706, 527698, 529865, 529373, 534579, 528620, 529135, 527526, 529424, 528630, 528006, 530310, 526802, 535029, 532985, 534183, 528299, 534092, 530544, 534788, 530381, 534324, 530384, 527957, 533723, 535163, 522979, 528931, 534756, 535158, 530670, 5290481, 527883, 534053, 530170, 5291719, 534556, 529736, 533736, 534626, 534478, 5290402, 534938, 5288249, 535240, 530431, 5292489, 529386, 535381, 535137, 533968, 532349, 535338, 528019, 529483, 529821, 528812, 535054, 529729, 5299603, 535392, 533886, 534817, 529528, 534130, 529764, 530101, 533983, 528113, 527524, 5279442, 5275212, 530297, 5287279, 5305129, 530624, 535246, 527829, 528653, 5278331, 5282839, 534857, 534491, 530157]\n",
      "nasogastric_tube \t\t ['slight', 'none', 'significant', nan]\n",
      "peristalsis \t\t ['absent', 'hypomotile', 'normal', 'hypermotile', nan, 'distend_small']\n",
      "outcome \t\t ['died', 'euthanized', 'lived']\n",
      "pain \t\t ['depressed', 'mild_pain', 'extreme_pain', 'alert', 'severe_pain', nan, 'slight']\n",
      "mucous_membrane \t\t ['dark_cyanotic', 'pale_cyanotic', 'pale_pink', 'normal_pink', 'bright_pink', 'bright_red', nan]\n",
      "nasogastric_reflux \t\t ['less_1_liter', 'more_1_liter', 'none', nan, 'slight']\n",
      "surgical_lesion \t\t ['yes', 'no']\n",
      "peripheral_pulse \t\t ['reduced', 'normal', nan, 'absent', 'increased']\n",
      "capillary_refill_time \t\t ['more_3_sec', 'less_3_sec', nan, '3']\n",
      "age \t\t ['adult', 'young']\n",
      "abdomen \t\t ['distend_small', 'distend_large', 'normal', 'firm', nan, 'other']\n",
      "temp_of_extremities \t\t ['cool', 'cold', 'normal', 'warm', nan]\n",
      "surgery \t\t ['yes', 'no']\n",
      "abdominal_distention \t\t ['slight', 'moderate', 'none', 'severe', nan]\n",
      "cp_data \t\t ['no', 'yes']\n",
      "rectal_exam_feces \t\t ['decreased', 'absent', nan, 'normal', 'increased', 'serosanguious']\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = list(set(df_train.columns) - set(df_train._get_numeric_data().columns))\n",
    "print(f\"CATEGORIES IN COLUMNS\\n---------------------------------------------------------------------------\\n\")\n",
    "print(\"Column \\t\\t\\t\\t Unique Categories\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"{col} \\t\\t {list(df_train[col].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Hospital number needs to replaced by something in feature engineering\n",
    "> 2. There are many categories here that can use sequential encoding instead of one hot encoding but we need to know their starting index and order (also value for null values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'COLUMNS_TO_BE_DROPPED': ['id', 'hospital_number'], 'BINARY_COLUMNS': ['age', 'surgical_lesion', 'surgery', 'cp_data'], 'NUMERICAL_COLUMNS': ['rectal_temp', 'pulse', 'respiratory_rate', 'nasogastric_reflux_ph', 'packed_cell_volume', 'total_protein', 'abdomo_protein', 'lesion_1', 'lesion_2', 'lesion_3'], 'MULTI_TYPE_COLUMNS': ['abdomen', 'mucous_membrane'], 'ORDINAL_TYPE_COLUMNS': {'temp_of_extremities': {'cold': -2, 'cool': -1, 'normal': 0, 'warm': 1, 'nan': -1}, 'peripheral_pulse': {'absent': -2, 'reduced': -1, 'normal': 0, 'increased': 1, 'nan': -1}, 'capillary_refill_time': {'less_3_sec': -1, '3': 0, 'more_3_sec': 1, 'nan': -1}, 'pain': {'alert': 0, 'depressed': 1, 'slight': 2, 'moderate': 3, 'mild_pain': 4, 'severe_pain': 5, 'extreme_pain': 6, 'nan': 1}, 'peristalsis': {'hypermotile': -2, 'normal': -1, 'hypomotile': 0, 'absent': 1, 'nan': 0, 'distend_small': 2}, 'abdominal_distention': {'none': 0, 'slight': 1, 'moderate': 2, 'severe': 3, 'nan': 2}, 'nasogastric_tube': {'none': 0, 'slight': 1, 'significant': 2, 'nan': 1}, 'nasogastric_reflux': {'less_1_liter': -1, 'none': 0, 'more_1_liter': 1, 'nan': 1, 'slight': 0}, 'rectal_exam_feces': {'absent': -2, 'decreased': -1, 'normal': 0, 'increased': 1, 'nan': -2, 'serosanguious': -2}, 'abdomo_appearance': {'clear': 0, 'cloudy': 1, 'serosanguious': 2, 'nan': 2}}, 'TARGET': ['outcome']}\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/Regular_Processed/With_Ordinal_Encoding/Pos_and_Neg/encoding.json\", \"r\") as json_file:\n",
    "    ENCODINGS = json.load(json_file)\n",
    "\n",
    "print(ENCODINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TO_BE_DROPPED = ENCODINGS['COLUMNS_TO_BE_DROPPED']\n",
    "BINARY_COLUMNS = ENCODINGS['BINARY_COLUMNS']\n",
    "NUMERICAL_COLUMNS = ENCODINGS['NUMERICAL_COLUMNS']\n",
    "MULTI_TYPE_COLUMNS = ENCODINGS[\"MULTI_TYPE_COLUMNS\"]\n",
    "ORDINAL_TYPE_COLUMNS = ENCODINGS[\"ORDINAL_TYPE_COLUMNS\"]\n",
    "TARGET = [\"outcome\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Formatting\n",
    "This includes one-hot encoding, binary encoding, and ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocess_num_data(train_df: pd.DataFrame, test_df: pd.DataFrame, NUMERICAL_COLUMNS: list):\n",
    "    drop_cols = list(set(train_df.columns) - set(NUMERICAL_COLUMNS))\n",
    "    train_df_temp = train_df.drop(drop_cols, axis=1)\n",
    "    test_df_temp = test_df.drop(drop_cols, axis=1)\n",
    "    train_arr = train_df_temp.reindex(NUMERICAL_COLUMNS, axis=1).to_numpy()\n",
    "    test_arr = test_df_temp.reindex(NUMERICAL_COLUMNS, axis=1).to_numpy()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    train_arr_scaled = scaler.fit_transform(train_arr)\n",
    "    test_arr_scaled = scaler.transform(test_arr)\n",
    "\n",
    "    train_df_scaled = pd.DataFrame(data=train_arr_scaled, columns=NUMERICAL_COLUMNS)\n",
    "    test_df_scaled = pd.DataFrame(data=test_arr_scaled, columns=NUMERICAL_COLUMNS)\n",
    "\n",
    "    return train_df_scaled, test_df_scaled\n",
    "\n",
    "def _preprocess_cat_data(df: pd.DataFrame, BINARY_COLUMNS: list, MULTI_TYPE_COLUMNS: list, ORDINAL_TYPE_COLUMNS: dict=None, possible_values_dict: dict=None, type_limit=10) -> pd.DataFrame:\n",
    "    \"\"\"Preprocesses categorical data.\n",
    "    ### Parameters\n",
    "    possible_values_dict - Contains the possible values of columns for consistant encoding in train and test. (None if training data is being sent)\n",
    "    ### Returns\n",
    "    (df, possible_values_dict) for training data\\n  \n",
    "    (df, None) for test data\n",
    "    \"\"\"\n",
    "    def get_possible_values(df_col: pd.Series) -> list:\n",
    "        \"\"\"Returns the possible values of a categorical column (removes nan/null values)\"\"\"\n",
    "        possible_values = list(df_col.unique())\n",
    "        possible_values_2 = []\n",
    "        for pv in possible_values:\n",
    "            if not pd.isna(pv):\n",
    "                possible_values_2.append(pv)\n",
    "        return possible_values_2\n",
    "    \n",
    "    if ORDINAL_TYPE_COLUMNS is None:\n",
    "        ORDINAL_TYPE_COLUMNS = {}\n",
    "\n",
    "    # Conflict Checking\n",
    "    ord_cols_set, mult_cols_set, bin_cols_set = set(ORDINAL_TYPE_COLUMNS.keys()), set(MULTI_TYPE_COLUMNS), set(BINARY_COLUMNS)\n",
    "    if not ord_cols_set.isdisjoint(mult_cols_set):\n",
    "        raise Exception(f\"Data Conflict: ORDINAL_TYPE_COLUMNS and MULTI_TYPE_COLUMNS both contain columns {ord_cols_set.intersection(mult_cols_set)}\")\n",
    "    elif not ord_cols_set.isdisjoint(bin_cols_set):\n",
    "        raise Exception(f\"Data Conflict: ORDINAL_TYPE_COLUMNS and BINARY_COLUMNS both have contain columns {ord_cols_set.intersection(bin_cols_set)}\")\n",
    "    elif not mult_cols_set.isdisjoint(bin_cols_set):\n",
    "        raise Exception(f\"Data Conflict: MULTI_TYPE_COLUMNS and BINARY_COLUMNS both have contain columns {mult_cols_set.intersection(bin_cols_set)}\")\n",
    "    \n",
    "    # Find the correct mode\n",
    "    if possible_values_dict is None:\n",
    "        train_mode = True\n",
    "        possible_values_dict = {}\n",
    "    else:\n",
    "        train_mode = False\n",
    "    \n",
    "    # 2) Binary columns\n",
    "    for bc in BINARY_COLUMNS:\n",
    "        if df[bc].nunique() != 2:\n",
    "            raise Exception(f\"Binary Column {bc} is not binary it has {df[bc].nunique()} possible values.\")\n",
    "        possible_values = list(df[bc].unique()) if train_mode else possible_values_dict[bc]\n",
    "        if train_mode:\n",
    "            possible_values_dict[bc] = possible_values\n",
    "        value_mapping = {possible_values[0]: 1, possible_values[1]: 0}\n",
    "        new_col_name = f\"{bc}_is_{possible_values[0]}\"\n",
    "        new_col = [value_mapping[val] for val in df[bc]]\n",
    "        df[new_col_name] = new_col\n",
    "    df = df.drop(BINARY_COLUMNS, axis=1)\n",
    "    \n",
    "    # 3) MULTI TYPE COLUMNS\n",
    "    for mc in MULTI_TYPE_COLUMNS:\n",
    "        if df[mc].nunique() > type_limit:\n",
    "            raise Exception(f\"Column {mc} has {df[mc].nunique()} values which exceeds the type limit of {type_limit}\")\n",
    "        possible_values = get_possible_values(df[mc]) if train_mode else possible_values_dict[mc]\n",
    "        if train_mode:\n",
    "            possible_values_dict[mc] = possible_values\n",
    "        value_mapping = {possible_values[i]: i for i in range(len(possible_values))}\n",
    "        new_col_names = [f\"{mc}_is_{pv}\" for pv in possible_values]\n",
    "        new_cols = np.zeros((len(possible_values), len(df)), dtype=np.int8)\n",
    "        col = list(df[mc])\n",
    "        for i in range(len(col)):\n",
    "            # For null and unseen values will be zero for all columns\n",
    "            if not(pd.isna(col[i])) and (col[i] in value_mapping):\n",
    "                new_cols[value_mapping[col[i]]][i] = 1\n",
    "\n",
    "        for i in range(len(possible_values)):\n",
    "            df[new_col_names[i]] = new_cols[i]\n",
    "    df = df.drop(MULTI_TYPE_COLUMNS, axis=1)\n",
    "\n",
    "    # 4) ORDINAL COLUMNS\n",
    "    for oc, value_mapping in ORDINAL_TYPE_COLUMNS.items():\n",
    "        null_value = value_mapping['nan']\n",
    "        col = list(df[oc])\n",
    "        new_col = []\n",
    "        for i in range(len(col)):\n",
    "            if pd.isna(col[i]):\n",
    "                new_col.append(null_value)\n",
    "            elif col[i] in value_mapping:\n",
    "                new_col.append(value_mapping[col[i]])\n",
    "            else:\n",
    "                raise Exception(f\"Unknown Value: {col[i]} found in column {oc}\")\n",
    "        df[oc] = new_col\n",
    "\n",
    "\n",
    "    return df, possible_values_dict\n",
    "\n",
    "def preprocess_data(train_df: pd.DataFrame, test_df: pd.DataFrame, COLUMNS_TO_BE_DROPPED: list,BINARY_COLUMNS: list, MULTI_TYPE_COLUMNS: list, NUMERICAL_COLUMNS: list, ORDINAL_TYPE_COLUMNS: dict = None, type_limit=10):\n",
    "    \"\"\"Handles all data preprocessing including One Hot Encoding and Standrad Scalar\n",
    "    ### Returns\n",
    "    (train_df, test_df) as pd.Dataframes after the processing\n",
    "    ### Note\n",
    "    Please remove target column from train data before processing, the dataframes need to have the same columns\"\"\"\n",
    "    # Check\n",
    "    if set(train_df.columns) != set(test_df.columns):\n",
    "        raise Exception(\"Train and Test data should have the same columns. (Please remove target from train data)\")\n",
    "    \n",
    "    # 1) Drop unwanted columns\n",
    "    train_df = train_df.drop(COLUMNS_TO_BE_DROPPED, axis=1)\n",
    "    test_df = test_df.drop(COLUMNS_TO_BE_DROPPED, axis=1)\n",
    "\n",
    "    # 2) PreProcess categorical data\n",
    "    train_df, possible_values_dict = _preprocess_cat_data(df=train_df, BINARY_COLUMNS=BINARY_COLUMNS, MULTI_TYPE_COLUMNS=MULTI_TYPE_COLUMNS, ORDINAL_TYPE_COLUMNS=ORDINAL_TYPE_COLUMNS, type_limit=type_limit, possible_values_dict=None)\n",
    "    test_df, _ = _preprocess_cat_data(df=test_df, BINARY_COLUMNS=BINARY_COLUMNS, MULTI_TYPE_COLUMNS=MULTI_TYPE_COLUMNS, ORDINAL_TYPE_COLUMNS=ORDINAL_TYPE_COLUMNS, type_limit=type_limit, possible_values_dict=possible_values_dict)\n",
    "\n",
    "    # 3) Preprocess numerical data\n",
    "    train_df_scaled, test_df_scaled = _preprocess_num_data(train_df= train_df, test_df=test_df, NUMERICAL_COLUMNS=NUMERICAL_COLUMNS)\n",
    "    for col in NUMERICAL_COLUMNS:\n",
    "        train_df[col] = train_df_scaled[col]\n",
    "        test_df[col] = test_df_scaled[col]\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do data preprocessing\n",
    "train_df_processed, test_df_processed = preprocess_data(train_df=df_train.drop(['outcome'], axis=1), test_df=df_test, COLUMNS_TO_BE_DROPPED=COLUMNS_TO_BE_DROPPED, BINARY_COLUMNS=BINARY_COLUMNS, MULTI_TYPE_COLUMNS=MULTI_TYPE_COLUMNS, NUMERICAL_COLUMNS=NUMERICAL_COLUMNS, ORDINAL_TYPE_COLUMNS=ORDINAL_TYPE_COLUMNS)\n",
    "\n",
    "# Handle outcome (target)\n",
    "possible_outcome_values = list(df_train['outcome'].unique())\n",
    "outcome_value_dict = {possible_outcome_values[i] : i for i in range(len(possible_outcome_values))}\n",
    "train_df_processed['outcome'] = [outcome_value_dict[list(df_train['outcome'])[i]] for i in range(len(df_train['outcome']))]\n",
    "\n",
    "# Do train valid split (there is a bug with scikit-learn which is causing a lot of NaN values to appear in the sparse dataset so we have to resort to this)\n",
    "train_df, valid_df = train_test_split(train_df_processed, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['died', 'euthanized', 'lived']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_outcome_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 988 entries, 284 to 350\n",
      "Data columns (total 36 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   rectal_temp                       988 non-null    float64\n",
      " 1   pulse                             988 non-null    float64\n",
      " 2   respiratory_rate                  988 non-null    float64\n",
      " 3   temp_of_extremities               988 non-null    int64  \n",
      " 4   peripheral_pulse                  988 non-null    int64  \n",
      " 5   capillary_refill_time             988 non-null    int64  \n",
      " 6   pain                              988 non-null    int64  \n",
      " 7   peristalsis                       988 non-null    int64  \n",
      " 8   abdominal_distention              988 non-null    int64  \n",
      " 9   nasogastric_tube                  988 non-null    int64  \n",
      " 10  nasogastric_reflux                988 non-null    int64  \n",
      " 11  nasogastric_reflux_ph             988 non-null    float64\n",
      " 12  rectal_exam_feces                 988 non-null    int64  \n",
      " 13  packed_cell_volume                988 non-null    float64\n",
      " 14  total_protein                     988 non-null    float64\n",
      " 15  abdomo_appearance                 988 non-null    int64  \n",
      " 16  abdomo_protein                    988 non-null    float64\n",
      " 17  lesion_1                          988 non-null    float64\n",
      " 18  lesion_2                          988 non-null    float64\n",
      " 19  lesion_3                          988 non-null    float64\n",
      " 20  age_is_adult                      988 non-null    int64  \n",
      " 21  surgical_lesion_is_yes            988 non-null    int64  \n",
      " 22  surgery_is_yes                    988 non-null    int64  \n",
      " 23  cp_data_is_no                     988 non-null    int64  \n",
      " 24  abdomen_is_distend_small          988 non-null    int8   \n",
      " 25  abdomen_is_distend_large          988 non-null    int8   \n",
      " 26  abdomen_is_normal                 988 non-null    int8   \n",
      " 27  abdomen_is_firm                   988 non-null    int8   \n",
      " 28  abdomen_is_other                  988 non-null    int8   \n",
      " 29  mucous_membrane_is_dark_cyanotic  988 non-null    int8   \n",
      " 30  mucous_membrane_is_pale_cyanotic  988 non-null    int8   \n",
      " 31  mucous_membrane_is_pale_pink      988 non-null    int8   \n",
      " 32  mucous_membrane_is_normal_pink    988 non-null    int8   \n",
      " 33  mucous_membrane_is_bright_pink    988 non-null    int8   \n",
      " 34  mucous_membrane_is_bright_red     988 non-null    int8   \n",
      " 35  outcome                           988 non-null    int64  \n",
      "dtypes: float64(10), int64(15), int8(11)\n",
      "memory usage: 211.3 KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to arrays\n",
    "y_train = train_df['outcome'].to_numpy()\n",
    "y_valid = valid_df['outcome'].to_numpy()\n",
    "\n",
    "# Reordering columns in train, valid and test dataset before converting to array\n",
    "column_order = list(train_df.drop(['outcome'], axis=1).columns)\n",
    "X_train = train_df.drop(['outcome'], axis=1).reindex(column_order, axis=1).to_numpy()\n",
    "X_valid = valid_df.drop(['outcome'], axis=1).reindex(column_order, axis=1).to_numpy()\n",
    "X_test = test_df_processed.reindex(column_order, axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the processed data as dataframes\n",
    "SAVE_DIR = \"data/Regular_Processed/With_Ordinal_Encoding/Pos_and_Neg\"\n",
    "train_df.to_csv(os.path.join(SAVE_DIR, 'train_processed.csv'))\n",
    "valid_df.to_csv(os.path.join(SAVE_DIR, 'valid_processed.csv'))\n",
    "test_df_processed.to_csv(os.path.join(SAVE_DIR, 'test_processed.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(SAVE_DIR, 'X_train.npy'), X_train)\n",
    "np.save(os.path.join(SAVE_DIR, 'X_valid.npy'), X_valid)\n",
    "np.save(os.path.join(SAVE_DIR, 'X_test.npy'), X_test)\n",
    "np.save(os.path.join(SAVE_DIR, 'y_train.npy'), y_train)\n",
    "np.save(os.path.join(SAVE_DIR, 'y_valid.npy'), y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Data Splitting\n",
    "Data splitting for the autoencoder (no y values involved and we can use the test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1647, 66)\n",
      "(412, 66)\n"
     ]
    }
   ],
   "source": [
    "# train_df_processed, test_df_processed\n",
    "merged_df = pd.concat([train_df_processed, test_df_processed], ignore_index=True)\n",
    "\n",
    "autoencoder_train, autoencoder_test = train_test_split(merged_df.drop(['outcome'], axis=1), test_size=0.2, shuffle=True)\n",
    "autoencoder_train_arr = autoencoder_train.to_numpy()\n",
    "autoencoder_test_arr = autoencoder_test.to_numpy()\n",
    "print(f\"{autoencoder_train_arr.shape}\\n{autoencoder_test_arr.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/Autoencoder_processed/Autoencoder_train.npy', autoencoder_train_arr)\n",
    "np.save('data/Autoencoder_processed/Autoencoder_test.npy', autoencoder_test_arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LearnPyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
